{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Neural Networks\n",
    "\n",
    "Andrei Gabriel Popescu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv\n",
    "\n",
    "# TSNE\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information about the dataset\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of degrees for each node\n",
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "\n",
    "# Count the number of nodes for each degree\n",
    "numbers = Counter(degrees)\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "plt.bar(numbers.keys(),\n",
    "        numbers.values(),\n",
    "        color='#0A047A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "      Graph Convolutional Network\n",
    "      made using the architecture from the homework paper\n",
    "\n",
    "      The changes are the inner layer with residual connections and the use of GELU instead of ReLU for the activation function.\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in:int, dim_h: int, dim_out: int, inner_num_layers: int = 3):\n",
    "      super().__init__()\n",
    "      self.gcn1 = GCNConv(in_channels=dim_in, out_channels=dim_h)\n",
    "      self.gcn_inner = GCNConv(in_channels=dim_h, out_channels=dim_h)\n",
    "      self.gcn2 = GCNConv(in_channels=dim_h, out_channels=dim_out)\n",
    "      self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=5e-3,\n",
    "                                        weight_decay=5e-4)\n",
    "      self.dropout_rate = 0.2\n",
    "      self.inner_num_layers = inner_num_layers\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        h = self.gcn1(h, edge_index)\n",
    "        h = F.gelu(h)\n",
    "        h = F.dropout(h, p=self.dropout_rate, training=self.training)\n",
    "        for _ in range(self.inner_num_layers):\n",
    "            old_h = h\n",
    "            h = self.gcn_inner(h, edge_index)\n",
    "            h = F.gelu(h)\n",
    "            h = F.dropout(h, p=self.dropout_rate, training=self.training)\n",
    "            h += old_h # residual connection\n",
    "            \n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Graph Attention Network\n",
    "        made using the architecture from the homework paper    \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in: int, dim_h: int, dim_out: int, heads:int = 8, inner_num_layers: int = 3):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(in_channels=dim_in, out_channels=dim_h, heads=heads)\n",
    "        self.gat_inner = GATv2Conv(in_channels=dim_h*heads, out_channels=dim_h*heads, heads=1)\n",
    "        self.gat2 = GATv2Conv(in_channels=dim_h*heads, out_channels=dim_out, heads=1)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                          lr=5e-3,\n",
    "                                          weight_decay=5e-4)\n",
    "\n",
    "        self.dropout_rate = 0.2\n",
    "        self.inner_num_layers = inner_num_layers\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.gelu(h)\n",
    "        h = F.dropout(h, p=self.dropout_rate, training=self.training)\n",
    "        for _ in range(self.inner_num_layers):\n",
    "            old_h = h\n",
    "            h = self.gat_inner(h, edge_index)\n",
    "            h = F.gelu(h)\n",
    "            h = F.dropout(h, p=self.dropout_rate, training=self.training)\n",
    "            # residual connection with respect to the number of heads\n",
    "            h += old_h\n",
    "            \n",
    "        h = self.gat2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data):\n",
    "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    epochs = 200\n",
    "\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "        train_losses.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # Validation\n",
    "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
    "                  f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                  f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    # Save the model into a folder callned GCN_models\n",
    "    if os.path.exists('GCN_models') == False:\n",
    "        os.mkdir('GCN_models')\n",
    "        \n",
    "    torch.save(model.state_dict(), f'GCN_models/{model.__class__.__name__}_{epochs}.pt')\n",
    "\n",
    "    # Plot the training and validation losses and accuracies\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].plot(train_losses, label='Train')\n",
    "    ax[0].plot(val_losses, label='Validation')\n",
    "    ax[0].legend()\n",
    "    ax[1].set_title('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].plot(train_accs, label='Train')\n",
    "    ax[1].plot(val_accs, label='Validation')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot into a folder called GCN_plots\n",
    "    if os.path.exists('GCN_plots') == False:\n",
    "        os.mkdir('GCN_plots')\n",
    "    \n",
    "    fig.savefig(f'GCN_plots/{model.__class__.__name__}_{epochs}.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing parameters\n",
    "embedding_dim = [128, 256]\n",
    "batch_size = 64\n",
    "\n",
    "# Create GCN model\n",
    "gcn = GCN(dim_in=dataset.num_features, dim_h=embedding_dim[0], dim_out=dataset.num_classes, inner_num_layers=4)\n",
    "print(gcn)\n",
    "\n",
    "# Train and test\n",
    "train(gcn, data)\n",
    "acc = test(gcn, data)\n",
    "print(f'\\nGCN test accuracy: {acc*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GAT model\n",
    "gat = GAT(dataset.num_features, 128, dataset.num_classes, heads=8, inner_num_layers=3)\n",
    "print(gat)\n",
    "\n",
    "# Train and test\n",
    "train(gat, data)\n",
    "acc = test(gat, data)\n",
    "print(f'\\nGAT test accuracy: {acc*100:.2f}%\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untrained GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_gat = GAT(dataset.num_features, 128, dataset.num_classes, heads=8, inner_num_layers=3)\n",
    "\n",
    "# Get embeddings\n",
    "h, _ = untrained_gat(data.x, data.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _ = gat(data.x, data.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's classifications\n",
    "_, out = gat(data.x, data.edge_index)\n",
    "\n",
    "# Calculate the degree of each node\n",
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "\n",
    "# Store accuracy scores and sample sizes\n",
    "accuracies = []\n",
    "sizes = []\n",
    "\n",
    "# Accuracy for degrees between 0 and 5\n",
    "for i in range(0, 6):\n",
    "  mask = np.where(degrees == i)[0]\n",
    "  accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))\n",
    "  sizes.append(len(mask))\n",
    "\n",
    "# Accuracy for degrees > 5\n",
    "mask = np.where(degrees > 5)[0]\n",
    "accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))\n",
    "sizes.append(len(mask))\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 9))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Accuracy score')\n",
    "ax.set_facecolor('#EFEEEA')\n",
    "plt.bar(['0','1','2','3','4','5','>5'],\n",
    "        accuracies,\n",
    "        color='#0A047A')\n",
    "for i in range(0, 7):\n",
    "    plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%',\n",
    "             ha='center', color='#0A047A')\n",
    "for i in range(0, 7):\n",
    "    plt.text(i, accuracies[i]//2, sizes[i],\n",
    "             ha='center', color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ppi dataset using PyTorch Geometric \n",
    "train_ppi = torch_geometric.datasets.PPI(root='ppi', split='train')\n",
    "val_ppi = torch_geometric.datasets.PPI(root='ppi', split='val')\n",
    "test_ppi = torch_geometric.datasets.PPI(root='ppi', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of the dataset\n",
    "print(train_ppi[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader with 64 batch size\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "train_loader = GeometricDataLoader(train_ppi, batch_size=64, shuffle=True)\n",
    "val_loader = GeometricDataLoader(val_ppi, batch_size=64, shuffle=True)\n",
    "test_loader = GeometricDataLoader(test_ppi, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Print a sample\n",
    "for batch in train_loader:\n",
    "    print(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_protein(model, train_loader, val_loader, test_loader):\n",
    "    \"\"\"Train the model on the training set.\"\"\"\n",
    "    optimizer = model.optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    epochs = 100\n",
    "\n",
    "    loader = train_loader\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        total_loss = 0\n",
    "        acc = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        # Train on batches\n",
    "        for data in loader:\n",
    "          optimizer.zero_grad()\n",
    "          _, out = model(data.x, data.edge_index)\n",
    "          loss = criterion(out, data.y)\n",
    "          total_loss += loss / len(loader)\n",
    "          acc += accuracy(out, data.y) / len(loader)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # Validation\n",
    "          val_loss, val_acc = test(model, val_loader)\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n",
    "                f'| Train Acc: {acc*100:>5.2f}% '\n",
    "                f'| Val Loss: {val_loss:.2f} '\n",
    "                f'| Val Acc: {val_acc*100:.2f}%')\n",
    "            \n",
    "    test_loss, test_acc = test(model, test_loader)\n",
    "    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    for data in loader:\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        loss += criterion(out, data.y) / len(loader)\n",
    "        acc += accuracy(out, data.y) / len(loader)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = GCN(dim_in=train_ppi.num_features, dim_out=train_ppi.num_classes, dim_h=256, inner_num_layers=3)\n",
    "\n",
    "# Train model\n",
    "model = train_protein(model, train_loader, val_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a67e1abd0d35ec53ce919d336f0d349bbdf2e5e7adabf005503a4ed55b683cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
